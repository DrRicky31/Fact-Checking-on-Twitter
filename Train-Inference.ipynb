{"cells":[{"cell_type":"markdown","id":"0ca2ac08","metadata":{"id":"0ca2ac08"},"source":["# Train and Inference"]},{"cell_type":"code","execution_count":null,"id":"0b2c9d63","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"0b2c9d63","executionInfo":{"status":"ok","timestamp":1718796777253,"user_tz":-120,"elapsed":302,"user":{"displayName":"Riccardo Felici","userId":"03523362669432416892"}},"outputId":"0aee31cb-8eab-44fa-95eb-ed0ce8b38fd5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["$('<div id=\"toc\"></div>').css({position: 'fixed', top: '120px', left: 0}).appendTo(document.body);\n","$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js');\n"]},"metadata":{}}],"source":["%%javascript\n","$('<div id=\"toc\"></div>').css({position: 'fixed', top: '120px', left: 0}).appendTo(document.body);\n","$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js');\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFkr4NP4O3uy","executionInfo":{"status":"ok","timestamp":1718796779480,"user_tz":-120,"elapsed":1800,"user":{"displayName":"Riccardo Felici","userId":"03523362669432416892"}},"outputId":"55da5fb3-507f-4125-d33a-8c35921f966f"},"id":"PFkr4NP4O3uy","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"id":"6469d3e8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6469d3e8","executionInfo":{"status":"ok","timestamp":1718796782828,"user_tz":-120,"elapsed":3349,"user":{"displayName":"Riccardo Felici","userId":"03523362669432416892"}},"outputId":"d37e898e-4749-4f9e-841a-450ec3e422f6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["import torch\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"id":"17630718","metadata":{"id":"17630718"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import json\n","from tqdm import tqdm, trange\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"id":"3f5549e0","metadata":{"id":"3f5549e0"},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","skf = StratifiedKFold(n_splits=5)\n"]},{"cell_type":"code","execution_count":null,"id":"0fcb18d4","metadata":{"id":"0fcb18d4"},"outputs":[],"source":["# change matplotlib parameters\n","plt.rcParams['figure.figsize'] = [15, 10]\n","plt.rcParams.update({'font.size': 30})"]},{"cell_type":"markdown","id":"2ceab410","metadata":{"id":"2ceab410"},"source":["# Training"]},{"cell_type":"markdown","id":"e89834b1","metadata":{"id":"e89834b1"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"id":"527a748f","metadata":{"id":"527a748f"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from collections import deque\n","import random\n","import copy\n","import os\n","\n","import pandas as pd\n","import numpy as np\n","import re\n","import json\n","from tqdm import tqdm, trange\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","import sklearn.metrics as metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertForPreTraining, BertModel, AutoTokenizer, BertForSequenceClassification, RobertaForSequenceClassification\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim import AdamW\n","\n","from tqdm.notebook import tqdm, trange\n","\n","#import emoji\n","from nltk.corpus import stopwords\n","\n","random_seed = 0\n","torch.manual_seed(random_seed)\n","random.seed(random_seed)\n","np.random.seed(random_seed)"]},{"cell_type":"markdown","id":"2137e1b7","metadata":{"id":"2137e1b7"},"source":["## Flags"]},{"cell_type":"code","execution_count":null,"id":"70bd0143","metadata":{"id":"70bd0143"},"outputs":[],"source":["normalize_test_flag = True\n","\n","# fold\n","k=0"]},{"cell_type":"markdown","id":"683c4c2f","metadata":{"id":"683c4c2f"},"source":["## Utils"]},{"cell_type":"code","execution_count":null,"id":"67ee0669","metadata":{"id":"67ee0669"},"outputs":[],"source":["import re\n","\n","def normalize_text(tweets):\n","    # Filtra solo i tweet che sono di tipo stringa\n","    tweets = [text for text in tweets if isinstance(text, str)]\n","\n","    normalized_tweets = []\n","    for text in tweets:\n","        text = text.replace('&amp;', '&')\n","        text = text.replace('\\xa0', '')\n","        text = re.sub(r'http\\S+', '', text)\n","        text = \" \".join(text.split())\n","        normalized_tweets.append(text)\n","\n","    return normalized_tweets\n"]},{"cell_type":"markdown","id":"f63a8b42","metadata":{"id":"f63a8b42"},"source":["## Load data"]},{"cell_type":"code","execution_count":null,"id":"f7716fd2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"f7716fd2","executionInfo":{"status":"ok","timestamp":1718796787289,"user_tz":-120,"elapsed":19,"user":{"displayName":"Riccardo Felici","userId":"03523362669432416892"}},"outputId":"80461c00-b6d6-4d9d-f536-f0a229610e02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla T4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"]},{"cell_type":"code","execution_count":null,"id":"f413dffc","metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"f413dffc","executionInfo":{"status":"ok","timestamp":1718796796135,"user_tz":-120,"elapsed":8864,"user":{"displayName":"Riccardo Felici","userId":"03523362669432416892"}},"outputId":"2a0eb0d7-92c3-434f-a00b-3ed81b6db204"},"outputs":[{"output_type":"stream","name":"stdout","text":["0         Koome: This court won’t sit next week but will...\n","1         Get Youtube promotion go viral click here to s...\n","2         \"Affordable Care Act\" replacement breaks Trump...\n","3         '@GeorgeJolly9 oh you know she is dead ass ser...\n","4         Media is treating wiretap claim like it's legi...\n","                                ...                        \n","381011    ICYMI, @SabrinaAnnLynn dropped a lyric video f...\n","381012    WorldStarHipHop Founder Lee \"Q\" O'Denat Dies a...\n","381013    “This world is but a canvas to our imagination...\n","381014    House Republicans release bill that would dism...\n","381015    Retweeted Citizen TV Kenya (@citizentvkenya): ...\n","Name: content, Length: 778248, dtype: object\n"]}],"source":["#data_path = '../data/covid-latent/'\n","#data_path = '../data/covid-latent/undersampling/'\n","#data_path = '../data/stance-detection-in-covid-19-tweets/stay_at_home_orders/' #face_masks, school_closures, stay_at_home_orders, fauci\n","data_path = '/content/gdrive/MyDrive/Colab Notebooks/data/russian-troll-tweets/'\n","#data_path = '../data/COVIDSenti/'\n","#data_path = '../data/birdwatch/'\n","#data_path = '../data/mediaeval22/old_task1/'\n","\n","filelist = os.listdir(data_path)\n","\n","# Prendi solo i primi tre file\n","filelist_subset = filelist[:2]\n","\n","# Leggi i primi tre file in dataframe\n","df_list = [pd.read_csv(data_path + file) for file in filelist_subset]\n","\n","test_df = df_list[k]\n","\n","train_df = pd.concat(df_list[:k]+df_list[k+1:])\n","test_df = pd.concat([train_df, test_df])\n","\n","\n","#tw_train = train_df['tweet'].tolist()\n","#tw_test = test_df['tweet'].tolist()\n","\n","tw_train = train_df['content']\n","tw_test = test_df['content']\n","# ids_test = test_df['tweet'].tolist()\n","\n","print(tw_test)\n","\n","if normalize_test_flag:\n","    tw_train = normalize_text(tw_train)\n","    tw_test = normalize_text(tw_test)\n","\n","#emotion\n","#train_df['emotion'][train_df['emotion'].isna()]='N'\n","#labels_train = train_df['emotion'].to_numpy()\n","#labels_train[labels_train=='N']=0\n","#labels_train[labels_train=='H']=1\n","#labels_train[labels_train=='A']=2\n","#labels_train[labels_train=='S']=3\n","#labels_train[labels_train=='F']=4\n","#labels_train = labels_train.tolist()\n","\n","#sentiment\n","#labels_train = train_df['label'].to_numpy()\n","#labels_train[labels_train=='neu']=1\n","#labels_train[labels_train=='pos']=2\n","#labels_train[labels_train=='neg']=0\n","#labels_train = labels_train.tolist()\n","\n","#political bias\n","labels_train = train_df['account_category'].to_numpy()\n","labels_train[labels_train==\"Unknown\"]=1\n","labels_train[labels_train==\"NonEnglish\"]=1\n","labels_train[labels_train==\"Commercial\"]=1\n","labels_train[labels_train==\"NewsFeed\"]=1\n","labels_train[labels_train==\"HashtagGamer\"]=1\n","labels_train[labels_train==\"Fearmonger\"]=1\n","labels_train[labels_train==\"LeftTroll\"]=0\n","labels_train[labels_train==\"RightTroll\"]=2\n","labels_train = labels_train.tolist()\n","\n","#emotion\n","#test_df['emotion'][test_df['emotion'].isna()]='N'\n","#labels_test = test_df['emotion'].to_numpy()\n","#labels_test[labels_test=='N']=0\n","#labels_test[labels_test=='H']=1\n","#labels_test[labels_test=='A']=2\n","#labels_test[labels_test=='S']=3\n","#labels_test[labels_test=='F']=4\n","#labels_test = labels_test.tolist()\n","\n","#sentiment\n","# labels_test = test_df['label'].to_numpy()\n","# labels_test[labels_test=='neu']=1\n","# labels_test[labels_test=='pos']=2\n","# labels_test[labels_test=='neg']=0\n","# labels_test = labels_test.tolist()\n","\n","#political bias\n","labels_test = test_df['account_category'].to_numpy()\n","labels_test[labels_test==\"Unknown\"]=1\n","labels_test[labels_test==\"NonEnglish\"]=1\n","labels_test[labels_test==\"Commercial\"]=1\n","labels_test[labels_test==\"NewsFeed\"]=1\n","labels_test[labels_test==\"HashtagGamer\"]=1\n","labels_test[labels_test==\"Fearmonger\"]=1\n","labels_test[labels_test==\"LeftTroll\"]=0\n","labels_test[labels_test==\"RightTroll\"]=2\n","labels_test = labels_test.tolist()\n","\n","ids_test = [i for i in range(0, len(test_df))]\n","\n","#labels_train = [[l-1 for l in L] for L in labels_train]\n","#labels_test = [[l-1 for l in L] for L in labels_test]\n"]},{"cell_type":"code","execution_count":null,"id":"5f57cca3","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"5f57cca3","executionInfo":{"status":"ok","timestamp":1718796796561,"user_tz":-120,"elapsed":428,"user":{"displayName":"Riccardo Felici","userId":"03523362669432416892"}},"outputId":"b5f52575-41bc-4d4a-9f89-d3c687bea34c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([6.3496, 1.9984, 2.9231], device='cuda:0')"]},"metadata":{},"execution_count":12}],"source":["weights = [len(labels_train)/w for w in [labels_train.count(a) for a in range(0, 3)]]\n","weights = torch.FloatTensor(weights).to(device)\n","weights"]},{"cell_type":"code","execution_count":null,"id":"a815a051","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a815a051","executionInfo":{"status":"ok","timestamp":1718796833338,"user_tz":-120,"elapsed":36778,"user":{"displayName":"Riccardo Felici","userId":"03523362669432416892"}},"outputId":"f213019d-5223-4007-cbdb-350fd8622506"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["341"]},"metadata":{},"execution_count":13}],"source":["tokenizer = AutoTokenizer.from_pretrained('digitalepidemiologylab/covid-twitter-bert')\n","\n","tokenized_input = tokenizer(tw_train)\n","\n","m = 0\n","for tokens in tokenized_input['input_ids']:\n","    if len(tokens)>m:\n","        m=len(tokens)\n","m"]},{"cell_type":"code","execution_count":null,"id":"633285bc","metadata":{"id":"633285bc"},"outputs":[],"source":["# Imposta il massimo numero di token per ogni input\n","MAX_LEN = 64\n","\n","# Tokenizza i dati in batch più piccoli per risparmiare memoria\n","def batch_tokenize(texts, tokenizer, batch_size=100, max_length=MAX_LEN):\n","    input_ids = []\n","    token_type_ids = []\n","    attention_masks = []\n","\n","    for i in range(0, len(texts), batch_size):\n","        batch_texts = texts[i:i+batch_size]\n","        tokenized_batch = tokenizer(batch_texts, max_length=max_length, padding='max_length', truncation=True)\n","\n","        input_ids.extend(tokenized_batch['input_ids'])\n","        token_type_ids.extend(tokenized_batch['token_type_ids'])\n","        attention_masks.extend(tokenized_batch['attention_mask'])\n","\n","        # Rilascia esplicitamente la memoria del batch processato\n","        del tokenized_batch\n","\n","    return input_ids, token_type_ids, attention_masks\n","\n","# Tokenizza i dati di addestramento e di test in batch\n","train_input_ids, train_token_type_ids, train_attention_mask = batch_tokenize(tw_train, tokenizer)\n","test_input_ids, test_token_type_ids, test_attention_mask = batch_tokenize(tw_test, tokenizer)\n","\n","# Converti le liste in tensori torch\n","train_input_ids = torch.tensor(train_input_ids, dtype=torch.long)\n","train_token_type_ids = torch.tensor(train_token_type_ids, dtype=torch.long)\n","train_attention_mask = torch.tensor(train_attention_mask, dtype=torch.long)\n","\n","test_input_ids = torch.tensor(test_input_ids, dtype=torch.long)\n","test_token_type_ids = torch.tensor(test_token_type_ids, dtype=torch.long)\n","test_attention_mask = torch.tensor(test_attention_mask, dtype=torch.long)\n","test_ids = torch.tensor(ids_test, dtype=torch.long)\n","\n","# Converti le etichette in tensori torch (assumendo che le etichette siano interi)\n","train_labels = torch.tensor(labels_train, dtype=torch.long)\n","test_labels = torch.tensor(labels_test, dtype=torch.long)"]},{"cell_type":"code","execution_count":null,"id":"8abcec39","metadata":{"id":"8abcec39"},"outputs":[],"source":["batch_size = 8 #\n","\n","train_data = TensorDataset(train_input_ids, train_attention_mask, train_labels, train_token_type_ids)\n","test_data = TensorDataset(test_input_ids, test_attention_mask, test_labels, test_token_type_ids, test_ids)\n","\n","\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"]},{"cell_type":"markdown","id":"a6f3ad8b","metadata":{"id":"a6f3ad8b"},"source":["## Models"]},{"cell_type":"code","execution_count":null,"id":"657e5a80","metadata":{"id":"657e5a80"},"outputs":[],"source":["class CovidTwitterBertClassifier(nn.Module):\n","\n","    def __init__(self, n_classes):\n","        super().__init__()\n","        self.n_classes = n_classes\n","        self.bert = BertForPreTraining.from_pretrained('digitalepidemiologylab/covid-twitter-bert-v2')\n","        self.bert.cls.seq_relationship = nn.Linear(1024, n_classes)\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input_ids, token_type_ids, input_mask):\n","        outputs = self.bert(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = input_mask)\n","\n","        logits = outputs[1]\n","\n","        return logits"]},{"cell_type":"code","execution_count":null,"id":"137d7cb3","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f5e6b9ab4198484bb908502ec0e7c193","6c45172b8f4a454cb352e5623ebf8256","db6b101ee7424407a48257876a73f206","0244c8066ff745a382e1a292daa9573f","dbf207aae14e4433ad6e6daea51bfaee","084d8f8f95c241ae9778104767bfb069","48b64d90264648238f9f351144632306","73d28defc042429c81262e446c6578da","142de95686974053960de93fdbddb12b","cd1a78cb98af477cbbcf5fa6cec6f840","8a80786e5c4f49f9861a949b8bd8053f","41d91993717f4d89ad832fa054ecde92","5937d1a8abda4010b6a2b2cf7d08f05e","6b897a76b04c4efebe1645fcb2c1378a","6da8155639c14437990bb732d23bc6c5","9caca6fdc4ae469b8159d9c54429efdd","bee44eb6807a4966b474f764084a06be","17a2c78f11204a8e82cc2fb6e804c9a1","59f6e8fb61244fa8a3b8f25cd0edcf6a","84ea980acc1841fdb0adc69913ed1537","73b7943f50494c81a79fb14a8478c236","7ec77ba09b25470e86e8417c0b440ed6"]},"id":"137d7cb3","executionInfo":{"status":"ok","timestamp":1718797201105,"user_tz":-120,"elapsed":32468,"user":{"displayName":"Riccardo Felici","userId":"03523362669432416892"}},"outputId":"cbd661fe-2efc-46b1-cdcb-5925f168a82d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/421 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5e6b9ab4198484bb908502ec0e7c193"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.35G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d91993717f4d89ad832fa054ecde92"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["CovidTwitterBertClassifier(\n","  (bert): BertForPreTraining(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","        (position_embeddings): Embedding(512, 1024)\n","        (token_type_embeddings): Embedding(2, 1024)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0-23): 24 x BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSdpaSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (cls): BertPreTrainingHeads(\n","      (predictions): BertLMPredictionHead(\n","        (transform): BertPredictionHeadTransform(\n","          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","          (transform_act_fn): GELUActivation()\n","          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (decoder): Linear(in_features=1024, out_features=30522, bias=True)\n","      )\n","      (seq_relationship): Linear(in_features=1024, out_features=3, bias=True)\n","    )\n","  )\n","  (sigmoid): Sigmoid()\n",")"]},"metadata":{},"execution_count":18}],"source":["model = CovidTwitterBertClassifier(3) # 5 for emotion and 3 for sentiment and political bias\n","\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"id":"eb60b67b","metadata":{"id":"eb60b67b"},"outputs":[],"source":["#optimizer_grouped_parameters\n","optimizer = AdamW(model.parameters(),\n","                  lr=1e-5,\n","                  #lr=3e-5,\n","                  weight_decay = 0.01)\n","\n","scheduler = ReduceLROnPlateau(optimizer, patience=4, factor=0.3)"]},{"cell_type":"code","execution_count":null,"id":"b509c9d7","metadata":{"id":"b509c9d7"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss(weight = weights)\n"]},{"cell_type":"markdown","id":"b0ad823b","metadata":{"id":"b0ad823b"},"source":["## Training loop"]},{"cell_type":"code","execution_count":null,"id":"89243993","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":211},"collapsed":true,"id":"89243993","executionInfo":{"status":"error","timestamp":1718805879265,"user_tz":-120,"elapsed":412,"user":{"displayName":"Riccardo Felici","userId":"03523362669432416892"}},"outputId":"e8ea63e2-b1c8-40fb-d6eb-191aa2914624"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a1f125198da9>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m999\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbest_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["epochs = 15\n","\n","best_F1 = 0\n","best_ACC = 0\n","best_loss = 999\n","best_acc = 0\n","best_state_dict = model.state_dict()\n","best_epoch = 0\n","\n","for e in trange(0, epochs, position=0, leave=True):\n","\n","    # Training\n","    print('Starting epoch ', e)\n","    model.train()\n","\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","\n","    for step, batch in enumerate(tqdm(train_dataloader)):\n","\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        b_input_ids, b_input_mask, b_labels, b_token_type_ids = batch\n","\n","        b_labels = b_labels.float()\n","        optimizer.zero_grad()\n","\n","        logits = model(b_input_ids, b_token_type_ids, b_input_mask)\n","\n","        loss = criterion(logits, b_labels.long())\n","        loss.backward()\n","        optimizer.step()\n","\n","        tr_loss += loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","\n","    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","\n","\n","    # eval\n","\n","    logits_full = []\n","    ground_truth_full = []\n","\n","    model.eval()\n","    eval_loss = 0\n","    steps=0\n","    for step, batch in enumerate(tqdm(test_dataloader)):\n","\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        b_input_ids, b_input_mask, b_labels, b_token_type_ids, b_ids = batch\n","\n","        b_labels = b_labels.float()\n","\n","        with torch.no_grad():\n","\n","            logits = model(b_input_ids, b_token_type_ids, b_input_mask)\n","            loss = criterion(logits, b_labels.long())\n","\n","\n","\n","        logits = logits.detach().cpu().tolist()\n","        logits_full.extend(logits)\n","        ground_truth = b_labels.detach().cpu().tolist()\n","        ground_truth_full.extend(ground_truth)\n","\n","        steps+=1\n","        eval_loss+=loss.detach().item()\n","\n","\n","    scheduler.step(eval_loss/steps)\n","    LOSS = eval_loss/steps\n","    F1 = metrics.f1_score(np.array(logits_full).argmax(axis=1), np.array(ground_truth_full), average='micro')\n","    ACC = metrics.accuracy_score(np.array(logits_full).argmax(axis=1), np.array(ground_truth_full))\n","\n","    if F1> best_F1:\n","        best_loss = LOSS\n","        best_F1 = F1\n","        best_ACC = ACC\n","        best_state_dict = copy.deepcopy(model.state_dict())\n","        best_epoch = e\n","\n","    print(\"\\t Eval loss: {}\".format(LOSS))\n","    print(\"\\t Eval F1: {}\".format(F1))\n","    print(\"\\t Eval ACC: {}\".format(ACC))\n","    print(\"---\"*25)\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"id":"9fd4526b","metadata":{"id":"9fd4526b"},"outputs":[],"source":["print(\"Best epoch\", best_epoch)\n","print(\"\\t Eval loss: {}\".format(best_loss))\n","print(\"\\t Eval F1: {}\".format(best_F1))\n","print(\"---\"*25)\n","print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"id":"681b07c7","metadata":{"id":"681b07c7"},"outputs":[],"source":["# Percorso in Google Drive dove salvare il modello\n","save_path = '/content/drive/My Drive/covid-latent/models/emotion_undersampling_CV{}_e{}_{}.pth'.format(k, best_epoch, round(best_F1, 3))\n","\n","# Salva il modello\n","torch.save(best_state_dict, save_path)"]},{"cell_type":"markdown","id":"ccf4f326","metadata":{"id":"ccf4f326"},"source":["# Inference"]},{"cell_type":"markdown","id":"87c2e034","metadata":{"id":"87c2e034"},"source":["## Load Data"]},{"cell_type":"code","execution_count":null,"id":"b9cdfb63","metadata":{"id":"b9cdfb63"},"outputs":[],"source":["#data_path = '../data/covid-latent/'\n","#data_path = '../data/covid-latent/undersampling/'\n","#data_path = '../data/stance-detection-in-covid-19-tweets/stay_at_home_orders/' #face_masks, school_closures, stay_at_home_orders, fauci\n","data_path = '/content/gdrive/MyDrive/Colab Notebooks/data/russian-troll-tweets/'\n","#data_path = '../data/COVIDSenti/'\n","#data_path = '../data/birdwatch/'\n","#data_path = '../data/mediaeval22/old_task1/'\n","\n","filelist = os.listdir(data_path)\n","\n","# Prendi solo i primi tre file\n","filelist_subset = filelist[:2]\n","\n","df_list = [pd.read_csv(data_path+file) for file in filelist_subset]\n","\n","\n","test_df = df_list[k]\n","\n","train_df = pd.concat(df_list[:k]+df_list[k+1:])\n","test_df = pd.concat([train_df, test_df])\n","\n","\n","tw_train = train_df['content']\n","tw_test = test_df['content']\n","#ids_test = test_df['tweet'].tolist()\n","\n","\n","if normalize_test_flag:\n","    tw_train = normalize_text(tw_train)\n","    tw_test = normalize_text(tw_test)\n","\n","#emotion\n","train_df['emotion'][train_df['emotion'].isna()]='N'\n","labels_train = train_df['emotion'].to_numpy()\n","labels_train[labels_train=='N']=0\n","labels_train[labels_train=='H']=1\n","labels_train[labels_train=='A']=2\n","labels_train[labels_train=='S']=3\n","labels_train[labels_train=='F']=4\n","labels_train = labels_train.tolist()\n","\n","#sentiment\n","labels_train = train_df['label'].to_numpy()\n","labels_train[labels_train=='neu']=1\n","labels_train[labels_train=='pos']=2\n","labels_train[labels_train=='neg']=0\n","labels_train = labels_train.tolist()\n","\n","#political bias\n","labels_train = train_df['account_category'].to_numpy()\n","labels_train[labels_train==\"Unknown\"]=1\n","labels_train[labels_train==\"NonEnglish\"]=1\n","labels_train[labels_train==\"Commercial\"]=1\n","labels_train[labels_train==\"NewsFeed\"]=1\n","labels_train[labels_train==\"HashtagGamer\"]=1\n","labels_train[labels_train==\"Fearmonger\"]=1\n","labels_train[labels_train==\"LeftTroll\"]=0\n","labels_train[labels_train==\"RightTroll\"]=2\n","labels_train = labels_train.tolist()\n","\n","#stance\n","labels_train = train_df['Stance'].to_numpy()\n","labels_train[labels_train==\"FAVOR\"]=2\n","labels_train[labels_train==\"NONE\"]=1\n","labels_train[labels_train==\"AGAINST\"]=0\n","labels_train = labels_train.tolist()\n","\n","#veracity\n","labels_train = train_df['note'].to_numpy()\n","labels_train[labels_train==\"MISINFORMED_OR_POTENTIALLY_MISLEADING\"]=0\n","labels_train[labels_train==\"NOT_MISLEADING\"]=1\n","labels_train = labels_train.tolist()\n","\n","#conspiracy\n","labels_train = train_df['conspiracy'].tolist()\n","\n","#emotion\n","test_df['emotion'][test_df['emotion'].isna()]='N'\n","labels_test = test_df['emotion'].to_numpy()\n","labels_test[labels_test=='N']=0\n","labels_test[labels_test=='H']=1\n","labels_test[labels_test=='A']=2\n","labels_test[labels_test=='S']=3\n","labels_test[labels_test=='F']=4\n","labels_test = labels_test.tolist()\n","\n","#sentiment\n","labels_test = test_df['label'].to_numpy()\n","labels_test[labels_test=='neu']=1\n","labels_test[labels_test=='pos']=2\n","labels_test[labels_test=='neg']=0\n","labels_test = labels_test.tolist()\n","\n","#political bias\n","labels_test = test_df['account_category'].to_numpy()\n","labels_test[labels_test==\"Unknown\"]=1\n","labels_test[labels_test==\"NonEnglish\"]=1\n","labels_test[labels_test==\"Commercial\"]=1\n","labels_test[labels_test==\"NewsFeed\"]=1\n","labels_test[labels_test==\"HashtagGamer\"]=1\n","labels_test[labels_test==\"Fearmonger\"]=1\n","labels_test[labels_test==\"LeftTroll\"]=0\n","labels_test[labels_test==\"RightTroll\"]=2\n","labels_test = labels_test.tolist()\n","\n","#stance\n","labels_test = test_df['Stance'].to_numpy()\n","labels_test[labels_test==\"FAVOR\"]=2\n","labels_test[labels_test==\"NONE\"]=1\n","labels_test[labels_test==\"AGAINST\"]=0\n","labels_test = labels_test.tolist()\n","\n","#veracity\n","labels_test = test_df['note'].to_numpy()\n","labels_test[labels_test==\"MISINFORMED_OR_POTENTIALLY_MISLEADING\"]=0\n","labels_test[labels_test==\"NOT_MISLEADING\"]=1\n","labels_test = labels_test.tolist()\n","\n","#conspiracy\n","labels_test = test_df['conspiracy'].tolist()\n","\n","\n","ids_test = [i for i in range(0, len(test_df))]\n","\n","#labels_train = [[l-1 for l in L] for L in labels_train]\n","#labels_test = [[l-1 for l in L] for L in labels_test]\n"]},{"cell_type":"markdown","id":"1e16c764","metadata":{"id":"1e16c764"},"source":["## Load model"]},{"cell_type":"code","execution_count":null,"id":"96750d59","metadata":{"id":"96750d59"},"outputs":[],"source":["model.load_state_dict(torch.load('/content/drive/My Drive/covid-latent/models/emotion_undersampling_CV{}_e{}_{}.pth'.format(k, best_epoch, round(best_F1, 3))))\n","model.eval()\n"]},{"cell_type":"code","execution_count":null,"id":"32f2e166","metadata":{"scrolled":true,"id":"32f2e166"},"outputs":[],"source":["logits_full = []\n","ground_truth_full = []\n","ids_full = []\n","\n","eval_loss = 0\n","steps=0\n","for step, batch in enumerate(tqdm(test_dataloader)):\n","\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","\n","    b_input_ids, b_input_mask, b_labels, b_token_type_ids, test_ids = batch\n","\n","    b_labels = b_labels.float()\n","\n","    with torch.no_grad():\n","\n","        logits = model(b_input_ids, b_token_type_ids, b_input_mask)\n","        #loss = criterion(logits, b_labels.long())\n","\n","\n","\n","    logits = logits.detach().cpu().tolist()\n","    logits_full.extend(logits)\n","    ground_truth = b_labels.detach().cpu().tolist()\n","    ground_truth_full.extend(ground_truth)\n","    ids = test_ids.detach().cpu().tolist()\n","    ids_full.extend(ids)\n","    steps+=1\n","    #eval_loss+=loss.detach().item()\n","\n","scheduler.step(eval_loss/steps)\n","LOSS = eval_loss/steps\n","F1 = metrics.f1_score(np.array(logits_full).argmax(axis=1), np.array(ground_truth_full), average='micro')\n","ACC = metrics.accuracy_score(np.array(logits_full).argmax(axis=1), np.array(ground_truth_full))\n","\n","\n","print(\"\\t Eval loss: {}\".format(LOSS))\n","print(\"\\t Eval F1: {}\".format(F1))\n","print(\"\\t Eval ACC: {}\".format(ACC))\n","print(\"---\"*25)\n","print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"id":"09b7bdb6","metadata":{"id":"09b7bdb6"},"outputs":[],"source":["df = pd.DataFrame()\n","\n","df['ids'] = ids_full\n","df['emotion'] = np.array(logits_full).argmax(axis=1).tolist()\n","#df.to_csv(data_path+'masks'+str(k)+'.csv', index=False)\n","df.to_csv(data_path+'emotion_full.csv', index=False)"]},{"cell_type":"markdown","id":"c2ad449f","metadata":{"id":"c2ad449f"},"source":["# Visu"]},{"cell_type":"code","execution_count":null,"id":"0f8a0cbe","metadata":{"id":"0f8a0cbe"},"outputs":[],"source":["A = np.zeros((3, 5))\n","\n","for i in trange(0, len(df)):\n","    A[test_df['conspiracy'].tolist()[i]][df.sort_values(by='ids')['emotion'].tolist()[i]]+=1\n","for i in range(0, 3):\n","    A[i,:] = A[i,:]/A[i,:].sum()\n","A"]},{"cell_type":"code","execution_count":null,"id":"4b422e71","metadata":{"scrolled":false,"id":"4b422e71"},"outputs":[],"source":["#NHASF\n","#sns.light_palette(\"seagreen\", as_cmap=True)\n","sns.heatmap(A, cmap = sns.light_palette(\"darkred\", as_cmap=True), yticklabels=['No Conspiracy', 'Discussing', 'Promoting'], xticklabels=['N', 'H', 'A', 'S', 'F'])\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f5e6b9ab4198484bb908502ec0e7c193":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c45172b8f4a454cb352e5623ebf8256","IPY_MODEL_db6b101ee7424407a48257876a73f206","IPY_MODEL_0244c8066ff745a382e1a292daa9573f"],"layout":"IPY_MODEL_dbf207aae14e4433ad6e6daea51bfaee"}},"6c45172b8f4a454cb352e5623ebf8256":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_084d8f8f95c241ae9778104767bfb069","placeholder":"​","style":"IPY_MODEL_48b64d90264648238f9f351144632306","value":"config.json: 100%"}},"db6b101ee7424407a48257876a73f206":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_73d28defc042429c81262e446c6578da","max":421,"min":0,"orientation":"horizontal","style":"IPY_MODEL_142de95686974053960de93fdbddb12b","value":421}},"0244c8066ff745a382e1a292daa9573f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd1a78cb98af477cbbcf5fa6cec6f840","placeholder":"​","style":"IPY_MODEL_8a80786e5c4f49f9861a949b8bd8053f","value":" 421/421 [00:00&lt;00:00, 24.3kB/s]"}},"dbf207aae14e4433ad6e6daea51bfaee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"084d8f8f95c241ae9778104767bfb069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48b64d90264648238f9f351144632306":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73d28defc042429c81262e446c6578da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"142de95686974053960de93fdbddb12b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd1a78cb98af477cbbcf5fa6cec6f840":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a80786e5c4f49f9861a949b8bd8053f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41d91993717f4d89ad832fa054ecde92":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5937d1a8abda4010b6a2b2cf7d08f05e","IPY_MODEL_6b897a76b04c4efebe1645fcb2c1378a","IPY_MODEL_6da8155639c14437990bb732d23bc6c5"],"layout":"IPY_MODEL_9caca6fdc4ae469b8159d9c54429efdd"}},"5937d1a8abda4010b6a2b2cf7d08f05e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bee44eb6807a4966b474f764084a06be","placeholder":"​","style":"IPY_MODEL_17a2c78f11204a8e82cc2fb6e804c9a1","value":"pytorch_model.bin: 100%"}},"6b897a76b04c4efebe1645fcb2c1378a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59f6e8fb61244fa8a3b8f25cd0edcf6a","max":1345068539,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84ea980acc1841fdb0adc69913ed1537","value":1345068539}},"6da8155639c14437990bb732d23bc6c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73b7943f50494c81a79fb14a8478c236","placeholder":"​","style":"IPY_MODEL_7ec77ba09b25470e86e8417c0b440ed6","value":" 1.35G/1.35G [00:29&lt;00:00, 29.8MB/s]"}},"9caca6fdc4ae469b8159d9c54429efdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bee44eb6807a4966b474f764084a06be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17a2c78f11204a8e82cc2fb6e804c9a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59f6e8fb61244fa8a3b8f25cd0edcf6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84ea980acc1841fdb0adc69913ed1537":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"73b7943f50494c81a79fb14a8478c236":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ec77ba09b25470e86e8417c0b440ed6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}